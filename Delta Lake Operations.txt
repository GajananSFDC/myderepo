from pyspark.sql import SparkSession
from delta import configure_spark_with_delta_pip

builder = SparkSession.builder \
    .appName("DeltaLakeExample") \
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog")

spark = configure_spark_with_delta_pip(builder).getOrCreate()
==========================================================================================================================

data = [(1, "Sachin Tendulkar", 35, "Cricket"),
        (2, "Saniya Mirza", 31, "Tennis"),
        (3, "Rohit Sharma", 29, "Cricket"),
        (4, "Arijit Singh", 30, "Singing"),
        (5, "Kartik Aaryan", 32, "Actor")]
columns = ["Id", "Name", "Age", "Field"]

df = spark.createDataFrame(data, columns)

df.write.format("delta").mode("overwrite").save("C:\\Users\\Gaju Gawande\\OneDrive\\Desktop\\Delta_Lake")
==========================================================================================================================
To Read Data 

df = spark.read.format("delta").load("C:\\Users\\Gaju Gawande\\OneDrive\\Desktop\\Delta_Lake")
df.show()
==========================================================================================================================

To Append Data 

new_data = [("3", "Virat Kohli", 35, "Cricket")]
new_df = spark.createDataFrame(new_data, columns)

new_df.write.format("delta").mode("append").save("C:\\Users\\Gaju Gawande\\OneDrive\\Desktop\\Delta_Lake")

==========================================================================================================================
Time Travel 

# पुराने version को read करें
df_old = spark.read.format("delta").option("versionAsOf", 0).load("C:\\Users\\Gaju Gawande\\OneDrive\\Desktop\\Delta_Lake")
df_old.show()
==========================================================================================================================